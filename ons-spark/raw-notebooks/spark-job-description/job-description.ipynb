{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Spark Job Description\n",
    "\n",
    "```{warning}\n",
    "This section is under construction.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spark UI is a great tool for monitoring Spark applications and troubleshooting slow jobs (see resources section for more information on the Spark UI). However, it is sometimes difficult to find the correct job number to drill down on a problem. \n",
    "\n",
    "There is a way to set the Spark job description in the script that makes finding the job in the Spark UI much easier.\n",
    "\n",
    "Let's start with a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"job-description-tip\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", 3)\n",
    "    .config(\"spark.sql.shuffle.partitions\", 12)\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "library(sparklyr)\n",
    "\n",
    "small_config <- sparklyr::spark_config()\n",
    "small_config$spark.executor.memory <- \"1g\"\n",
    "small_config$spark.executor.cores <- 1\n",
    "small_config$spark.dynamicAllocation.enabled <- \"true\"\n",
    "small_config$spark.dynamicAllocation.maxExecutors <- 3\n",
    "small_config$spark.sql.shuffle.partitions <- 12\n",
    "small_config$spark.shuffle.service.enabled <- \"true\"\n",
    "\n",
    "sc <- sparklyr::spark_connect(\n",
    "  master = \"yarn-client\",\n",
    "  app_name = \"small-session\",\n",
    "  config = small_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate a link to the Spark UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, IPython\n",
    "url = \"spark-%s.%s\" % (os.environ[\"CDSW_ENGINE_ID\"], os.environ[\"CDSW_DOMAIN\"])\n",
    "IPython.display.HTML(\"<a href=http://%s>Spark UI</a>\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "library(\"cdsw\")\n",
    "url = paste(\"spark-\", Sys.getenv(\"CDSW_ENGINE_ID\"), \".\", Sys.getenv(\"CDSW_DOMAIN\"), sep=\"\")\n",
    "html(paste(\"<a href=http://\", url, \">Spark UI</a>\", sep=\"\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Resources\n",
    "\n",
    "Spark at the ONS Articles:\n",
    "- [Spark Application and UI](../spark-concepts/spark-application-and-ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
