{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data in PySpark\n",
    "This chapter will go into more detail about the various methods available to read in data in PySpark. The previous chapter, [Introduction to PySpark](../pyspark-intro/pyspark-intro), briefly covered [`spark.read.csv()`](https://spark.apache.org/docs/latest/sql-data-sources-csv.html) and [`spark.read.parquet()`](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html) to read data in as a CSV and parquet file respectively.\n",
    "\n",
    "This chapter will provide more detail on when you would use [`spark.read.csv()`](https://spark.apache.org/docs/latest/sql-data-sources-csv.html) or [`spark.read.parquet()`](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html) as well as introducing new methods to read in data including Hive tables and ORC files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV files\n",
    "To read in a CSV file, you can use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+--------------------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+--------------------+---------------+----------------+---------+----------+---------------+----------------+\n",
      "|IncidentNumber|  DateTimeOfCall|CalYear|FinYear| TypeOfIncident|PumpCount|PumpHoursTotal|HourlyNotionalCost(£)|IncidentNotionalCost(£)|    FinalDescription|   AnimalGroupParent|      OriginofCall|        PropertyType| PropertyCategory|SpecialServiceTypeCategory|  SpecialServiceType| WardCode|                Ward|BoroughCode|             Borough|  StnGroundName|PostcodeDistrict|Easting_m|Northing_m|Easting_rounded|Northing_rounded|\n",
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+--------------------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+--------------------+---------------+----------------+---------+----------+---------------+----------------+\n",
      "|        139091|01/01/2009 03:01|   2009|2008/09|Special Service|      1.0|           2.0|                  255|                  510.0|DOG WITH JAW TRAP...|                 Dog|Person (land line)|House - single oc...|         Dwelling|      Other animal assi...|Animal assistance...|E05011467|Crystal Palace & ...|  E09000008|             Croydon|        Norbury|            SE19|     null|      null|         532350|          170050|\n",
      "|        275091|01/01/2009 08:51|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|ASSIST RSPCA WITH...|                 Fox|Person (land line)|            Railings|Outdoor Structure|      Other animal assi...|Animal assistance...|E05000169|            Woodside|  E09000008|             Croydon|       Woodside|            SE25| 534785.0|  167546.0|         534750|          167550|\n",
      "|       2075091|04/01/2009 10:07|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG CAUGHT IN DRA...|                 Dog|   Person (mobile)|      Pipe or drain |Outdoor Structure|      Animal rescue fro...|Animal rescue fro...|E05000558|  Carshalton Central|  E09000029|              Sutton|     Wallington|             SM5| 528041.0|  164923.0|         528050|          164950|\n",
      "|       2872091|05/01/2009 12:27|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|HORSE TRAPPED IN ...|               Horse|   Person (mobile)|Intensive Farming...|  Non Residential|      Animal rescue fro...|Animal rescue fro...|E05000330|           Harefield|  E09000017|          Hillingdon|        Ruislip|             UB9| 504689.0|  190685.0|         504650|          190650|\n",
      "|       3553091|06/01/2009 15:23|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|RABBIT TRAPPED UN...|              Rabbit|   Person (mobile)|House - single oc...|         Dwelling|      Other animal assi...|Animal assistance...|E05000310|            Gooshays|  E09000016|            Havering|    Harold Hill|             RM3|     null|      null|         554650|          192350|\n",
      "|       3742091|06/01/2009 19:30|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|ANIMAL TRAPPED BE...|Unknown - Heavy L...|Person (land line)|House - single oc...|         Dwelling|      Other animal assi...|Animal assistance...|E05000027|              Alibon|  E09000002|Barking and Dagenham|       Dagenham|            RM10|     null|      null|         549350|          184950|\n",
      "|       4011091|07/01/2009 06:29|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG WITH HEAD TRA...|                 Dog|Person (land line)|               Park |          Outdoor|      Other animal assi...|Animal assistance...|E05000591|             Cathall|  E09000031|      Waltham Forest|    Leytonstone|             E11| 539013.0|  186162.0|         539050|          186150|\n",
      "|       4211091|07/01/2009 11:55|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|LABRADOR FALLEN T...|                 Dog|   Person (mobile)|Lake/pond/reservoir |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000515|            Wanstead|  E09000026|           Redbridge|    Leytonstone|             E12| 541327.0|  186654.0|         541350|          186650|\n",
      "|       4306091|07/01/2009 13:48|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|SQUIRREL TRAPPED ...|            Squirrel|Person (land line)|House - single oc...|         Dwelling|      Animal rescue fro...|Wild animal rescu...|E05011470| New Addington North|  E09000008|             Croydon|      Addington|             CR0|     null|      null|         538750|          163350|\n",
      "|       4715091|07/01/2009 21:24|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG STUCK IN MUD,...|                 Dog|   Person (mobile)|        River/canal |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05009380|          Lea Bridge|  E09000012|             Hackney|Stoke Newington|              E5| 535425.0|  186743.0|         535450|          186750|\n",
      "|       5186091|08/01/2009 14:34|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|TO ASSIST RSPCA W...|                 Cat|Person (land line)|         Tree scrub |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000115|    Cray Valley West|  E09000006|             Bromley|      Orpington|             BR5| 546981.0|  169297.0|         546950|          169250|\n",
      "|       5363091|08/01/2009 19:23|   2009|2008/09|Special Service|      1.0|           2.0|                  255|                  510.0|ASSIST WILDLIFE H...|                Bird|   Person (mobile)|Lake/pond/reservoir |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000620|          Queenstown|  E09000032|          Wandsworth|        Clapham|            SW11| 528666.0|  177290.0|         528650|          177250|\n",
      "|       5682091|09/01/2009 11:01|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG TRAPPED IN BO...|                 Dog|   Person (mobile)|                Car |     Road Vehicle|      Other animal assi...|Animal assistance...|E05000535|    Camberwell Green|  E09000028|           Southwark|        Peckham|             SE5| 532478.0|  176515.0|         532450|          176550|\n",
      "|       5688091|09/01/2009 11:18|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|RUNNING CALL TO D...|                 Dog|Person (land line)|Other animal boar...|  Non Residential|      Other animal assi...|Animal assistance...|E05000034|               Heath|  E09000002|Barking and Dagenham|       Dagenham|            RM10| 549923.0|  186441.0|         549950|          186450|\n",
      "|       5724091|09/01/2009 12:40|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|ASSIST RSPCA WITH...|                 Cat|Person (land line)|         Tree scrub |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000528|      South Richmond|  E09000027|Richmond upon Thames|       Richmond|            TW10| 518497.0|  174567.0|         518450|          174550|\n",
      "|       5770091|09/01/2009 13:43|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|CAT STUCK UP TREE...|                 Cat|Person (land line)|         Tree scrub |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05011489|            Woodside|  E09000008|             Croydon|       Woodside|            SE25| 534865.0|  167671.0|         534850|          167650|\n",
      "|       5789091|09/01/2009 14:30|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|INJURED CAT UP TR...|                 Cat|Person (land line)|          Wasteland |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000453|      Telegraph Hill|  E09000023|            Lewisham|      New Cross|             SE4| 535913.0|  174968.0|         535950|          174950|\n",
      "|       5797091|09/01/2009 14:39|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG TRAPPED IN BR...|                 Dog|         Ambulance|Woodland/forest -...|          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000431|     Streatham South|  E09000022|             Lambeth|        Norbury|            SW16| 530995.0|  170839.0|         530950|          170850|\n",
      "|       6259091|10/01/2009 09:35|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|AFA ACTUATING IN ...|Unknown - Domesti...|Person (land line)|               Park |          Outdoor|      Animal rescue fro...|Animal rescue fro...|E05000540|       East Walworth|  E09000028|           Southwark|  Old Kent Road|            SE17| 532595.0|  178874.0|         532550|          178850|\n",
      "|       6270091|10/01/2009 10:09|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|INJURED DOG FOLLO...|                 Dog|Person (land line)|Road surface/pave...|          Outdoor|      Other animal assi...|Animal assistance...|E05000159|              Purley|  E09000008|             Croydon|         Purley|             CR8| 531679.0|  161982.0|         531650|          161950|\n",
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+--------------------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+--------------------+---------------+----------------+---------+----------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = (SparkSession.builder.master(\"local[2]\")\n",
    "         .appName(\"reading-data\")\n",
    "         .getOrCreate())\n",
    "\n",
    "animal_rescue = spark.read.csv(\"../data/animal_rescue.csv\", header = True, inferSchema = True)\n",
    "animal_rescue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note the two arguments we have provided to the `spark.read.csv()` function, `header` and `inferSchema`.\n",
    "\n",
    "By setting `header` to True, we're saying that we want the top row to be used as the column names. If we did not set this argument to True, then the top rows will be treated as the first row of data, and columns will be given a default name of \"_c1\", \"_c2\", \"_c3\" and so on.\n",
    "\n",
    "`inferSchema` is very important - a disadvantage of using a CSV file is that they are not associated with a schema in the same way parquet files are. By setting `inferSchema` to True, we're allowing the PySpark API to attempt to work out the schemas based on the contents of each column. If this were set to False, then each column would be set to a string datatype by default.\n",
    "\n",
    "Note that `inferSchema` isn't always completely correct - we can see this in the DateTimeOfCall column in the below code. It should be a date type, but it has been read in as a string type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- DateTimeOfCall: string (nullable = true)\n",
      " |-- CalYear: integer (nullable = true)\n",
      " |-- FinYear: string (nullable = true)\n",
      " |-- TypeOfIncident: string (nullable = true)\n",
      " |-- PumpCount: double (nullable = true)\n",
      " |-- PumpHoursTotal: double (nullable = true)\n",
      " |-- HourlyNotionalCost(£): integer (nullable = true)\n",
      " |-- IncidentNotionalCost(£): double (nullable = true)\n",
      " |-- FinalDescription: string (nullable = true)\n",
      " |-- AnimalGroupParent: string (nullable = true)\n",
      " |-- OriginofCall: string (nullable = true)\n",
      " |-- PropertyType: string (nullable = true)\n",
      " |-- PropertyCategory: string (nullable = true)\n",
      " |-- SpecialServiceTypeCategory: string (nullable = true)\n",
      " |-- SpecialServiceType: string (nullable = true)\n",
      " |-- WardCode: string (nullable = true)\n",
      " |-- Ward: string (nullable = true)\n",
      " |-- BoroughCode: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- StnGroundName: string (nullable = true)\n",
      " |-- PostcodeDistrict: string (nullable = true)\n",
      " |-- Easting_m: double (nullable = true)\n",
      " |-- Northing_m: double (nullable = true)\n",
      " |-- Easting_rounded: integer (nullable = true)\n",
      " |-- Northing_rounded: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "animal_rescue.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct this, we can either cast the column as a date type or we can provide a schema when reading it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- DateTimeOfCall: timestamp (nullable = true)\n",
      " |-- CalYear: integer (nullable = true)\n",
      " |-- TypeOfIncident: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"IncidentNumber\", StringType(), True),\n",
    "    StructField(\"DateTimeOfCall\", TimestampType(), True),\n",
    "    StructField(\"CalYear\", IntegerType(), True),\n",
    "    StructField(\"TypeOfIncident\", StringType(), True),])\n",
    "\n",
    "\n",
    "\n",
    "animal_rescue = spark.read.csv(path = \"../data/animal_rescue.csv\", header = True, schema = custom_schema)\n",
    "animal_rescue.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that DateTimeOfCall has now been read in correctly as a timestamp type. Also, providing a schema will improve the efficiency of the operation. This is because, in order to infer a schema, Spark needs to scan the dataset. A column could contain, for example, an integer for the first 1000 rows and a string for the 1001th row - in which case it would be inferred as a string, but this wouldn't be obvious from the first 1000 rows. Needing to sample the data in each column can be quite memory intensive. Providing a schema means that Spark no longer has to sample the data before reading it in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in parquet files\n",
    "To read in a parquet file, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_rescue = spark.read.parquet(\"../data/animal_rescue.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we didn't have to provide a schema or use the inferSchema argument - this is because parquet files already have a schema associated with them, which is stored in the metadata. This is one of the benefits of reading in from a parquet file as opposed to a CSV, and there are several more benefits, including: \n",
    "\n",
    "* Column-based format - parquet files are organised by columns, rather than by row. This allows for better compression and more efficient use of storage space, as columns typically contain similar data types and repeating values. Additionally, when accessing only specific columns, PySpark can skip reading in unnecessary data and only read in the columns of interest.\n",
    "* Predicate pushdown - parquet supports predicate pushdowns, this means if you read in the full dataset and then filter, the filter clause will be \"pushed down\" to where the data is stored, meaning it can be filtered before it is read in, reducing the amount of memory that the data will take up. \n",
    "* Compression - parquet has built-in compression methods to reduce the required storage space.\n",
    "* Complex data types - parquet files support complex data types such as nested data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in a Hive table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
